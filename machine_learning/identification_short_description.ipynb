{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проект: Идентификация пользователей по посещенным веб-страницам"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Цель проекта:** Научиться идентифицировать пользователей на основе паттернов поведения в Интернете (через анализ последовательностей посещенных ими сайтов).\n",
    "\n",
    "**Задачи проекта:**\n",
    "1. Преобразовать данные в формат, подходящий для анализа и решения задачи машинного обучения\n",
    "2. Выделить подвыборку, сформировать набор показателей для анализа и провести первичный анализ данных, оценить возможность выявления характерного поведения\n",
    "3. Решить задачу машинного обучения с помощью нескольких алгоритмов\n",
    "4. Выбрать алгоритм/ансамбль алгоритмов, дающий лучший результат\n",
    "\n",
    "**Затрагиваемые области Machine Learning:** Supervised Learning, Sequential Pattern Mining\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Описание данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Исходные данные взяты из [статьи](http://ceur-ws.org/Vol-1703/paper12.pdf) \"A Tool for Classification of Sequential Data\" и представляют собой набор файлов (по 1 файлу на каждого пользователя) с информацией о посещенных пользователями сайтах и временными метками перехода на каждую страницу. Пример:\n",
    "<center>user0001.csv</center>\n",
    "<style type=\"text/css\">\n",
    ".tg  {border-collapse:collapse;border-spacing:0;}\n",
    ".tg td{font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;}\n",
    ".tg th{font-family:Arial, sans-serif;font-size:14px;font-weight:normal;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;}\n",
    ".tg .tg-yw4l{vertical-align:top}\n",
    "</style>\n",
    "<table class=\"tg\">\n",
    "  <tr>\n",
    "    <th class=\"tg-031e\">timestamp</th>\n",
    "    <th class=\"tg-031e\">site</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-031e\">00:00:01</td>\n",
    "    <td class=\"tg-031e\">vk.com</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-yw4l\">00:00:11</td>\n",
    "    <td class=\"tg-yw4l\">google.com</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-031e\">00:00:16</td>\n",
    "    <td class=\"tg-031e\">vk.com</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-031e\">00:00:20</td>\n",
    "    <td class=\"tg-031e\">yandex.ru</td>\n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для дальнейшего анализа данные из файлов преобразуются в единый датасет, содержащий информацию о пользовательских сессиях, где под сессией понимается последовательность из N сайтов, подряд идущих в исходных файлах. При этом наименования всех сайтов, встречающихся в выборке кодируются и помещаются в ячейки датасета. Пример соответствующий таблице выше (N = 2, vk.com закодирован как 1, google.com - 2, yandex.ru - 3):\n",
    "<style type=\"text/css\">\n",
    ".tg  {border-collapse:collapse;border-spacing:0;}\n",
    ".tg td{font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;}\n",
    ".tg th{font-family:Arial, sans-serif;font-size:14px;font-weight:normal;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;}\n",
    ".tg .tg-s6z2{text-align:center}\n",
    ".tg .tg-baqh{text-align:center;vertical-align:top}\n",
    ".tg .tg-hgcj{font-weight:bold;text-align:center}\n",
    ".tg .tg-amwm{font-weight:bold;text-align:center;vertical-align:top}\n",
    "</style>\n",
    "<table class=\"tg\">\n",
    "  <tr>\n",
    "    <th class=\"tg-hgcj\">session_id</th>\n",
    "    <th class=\"tg-hgcj\">site1</th>\n",
    "    <th class=\"tg-hgcj\">site2</th>\n",
    "    <th class=\"tg-amwm\">user_id</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-s6z2\">1</td>\n",
    "    <td class=\"tg-s6z2\">1</td>\n",
    "    <td class=\"tg-s6z2\">2</td>\n",
    "    <td class=\"tg-baqh\">1</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-s6z2\">2</td>\n",
    "    <td class=\"tg-s6z2\">1</td>\n",
    "    <td class=\"tg-s6z2\">3</td>\n",
    "    <td class=\"tg-baqh\">1</td>\n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поскольку такой датасет содержит не вещественные, а категориальные признаки, строить модель непосредственно на нем нельзя. Требуется еще один этап преобразования - переход к идее мешка слов из анализа текстов и, соответственно, переход к разреженной матрице, где строкам соответствуют сессии из N сайтов, столбцам – индексы сайтов (их кодировки), а на пересечении строки и столбца стоит число k – cколько раз соответствующий сайт встретился в соответствующей сессии. Это будет сделано перед построением модели с использование библиотеки Scipy (функция csr_matrix).\n",
    "\n",
    "Далее будет использоваться датасет по 10 пользователям.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Первичный анализ данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Первичный анализ проводился при N=10 и скользящим окном в 10 сайтов (значит, что каждая строка исходных данных попадет только в одну сессию, если скользящее окно будет меньше длины сессии, сессии будут перекрываться)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В ходе него были проведены анализ распределения количества уникальных сайтов в сессиях, распределение частот посещения сайтов, проверка нормальности распределения целевого признака, вариативность поведения пользователей; определены наиболее часто посещаемые сайты."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Визуальный анализ признаков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее генерировались признаки, характеризующие поведение пользователей и анализировалось распределение признаков отдельно для каждого из пользователей. Это позволило выделить признаки, существенно варьирующиеся между пользователями и, соответственно, способными помочь в решении поставленной задачи."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Важно, что из графиков следует наличие существенных отличий в поведении пользователей, соответственно, скорее всего, получится построить модель, идентифицирующую пользователей, с высоким уровнем качества.***\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Применение алгоритмов машинного обучения "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Предобработка данных "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Датасет был предварительно преобразован в разреженную матрицу и разобит на обучающую и тестовую выборки в соотношении 0.7 и 0.3, также использовалась кросс-валидация для получения более объективной оценки качества (стратифицированная, 3-кратная, с перемешиванием)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Метрики качества"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для сопоставимости результатов необходимо использовать минимальное количество метрик оценки качества для задач классификации. Одной из наиболее прозрачных и легко интерпретируемых метрик является **ROC AUC**. Это площадь под ROC-кривой, где по оси Х откладываются значения метрики \n",
    "\n",
    "$$False Positive Rate (FPR) = FP / (FP + TN),$$ а по оси Y - $$True Positive Rate (TPR) = TP / (TP + FN),$$ где \n",
    "- FP - это количество ложных срабатываний алгоритма (алгоритм отнес к классу 1, хотя не должен был), \n",
    "- TP - количество верных срабатываний алгоритма, \n",
    "- FN - количество ложных пропусков (алгоритм отнес к классу 0, когда должен был отнести к классу 1), \n",
    "- TN - количество верных пропусков (верно отнесено к классу 0). \n",
    "\n",
    "Эта метрика удобна тем, что имеет ограниченный диапазон значений, которые она способна принимать, и является легко интерпретируемой: варьируется от 0 до 1, чем выше значение, тем выше качества, уровень 0.5 соответствует предсказаниям на уровне случайных чисел.\n",
    "Кроме того, она может принимать на вход как сами предсказанные метки классов, так и их вероятности. \n",
    "Но у нее есть и ограничение - она не может использоваться в задачах многоклассовой классификации (а у нас 10 пользователей, т.е. 10 классов), поэтому попробуем решить задачу в двух плоскостях: \n",
    "\n",
    "1. сравнивая 10 пользователей между собой. Здесь будет использоваться метрика **accuracy** *(доля правильно предсказанных меток классов, варьируется от 0 до 1, где 1 соответствует идеальной модели, не умеет работать с вероятностями и не чувствительна к несбалансированности выборки)*;\n",
    "2. сравнивая одного пользователя со всеми остальными. Здесь мы сможем перейти к метрике **ROC AUC**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выбор наиболее результативных алгоритмов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Были использованы 6 алгоритмов:\n",
    "- KNeighborsClassifier\n",
    "- RandomForestClassifier\n",
    "- LogisticRegression\n",
    "- Линейный SVM (LinearSVC)\n",
    "- SGDClassifier\n",
    "- Vowpal Wabbit\n",
    "\n",
    "В итоге для дальнейшей работы выбраны те, которые показали наилучшее качество при предсказании вероятностей меток классов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Добавление к модели дополнительных параметров"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "К модели добавлены ранее отобранные признаки, чтобы понять, улучшит ли это качество предсказания меток классов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Настройка параметров моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попытка улучшить результат путем оптимизации параметров моделей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***В реультате модели были проранжированы по качеству полученных результатов.***\n",
    "***Полученное решение имеет достаточно высокое качество (0.94790).***\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Применимость "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Такого рода задачи могут решаться для обеспечения безопасности (снижения вероятности или продолжительности несанкционированного использования аккаунтов пользователя), группировки аккаунтов или устройств (например, если пользователь может сидеть в интернете с рабочего компьютера, домашнего ноутбука и с телефона) и, как следствие, получения возможности проведения более глубокого анализа поведения потребителей услуг."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Что еще можно было сделать "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. entity recognition (преобразование наименований сайтов для исключение дубликатов, например, www.google.fr и www.google.com - 2 самых часто встречающихся сайта в датасете)\n",
    "2. уделить больше внимания feature engineering и проверять влияние признаков на модель с помощью алгоритмов feature selection\n",
    "3. примерение методов объединения моделей в ансамбли\n",
    "4. выбор параметров датасета: количества сайтов в сессии и ширины скользящего окна\n",
    "5. подбор параметров для случайного леса (с Tf-idf) - это долго\n",
    "6. применение модели к большей выборке (150 или 3000 пользователей)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
